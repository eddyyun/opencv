{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "#Templates for Rock, Paper, and Waving Gestures\n",
    "template = cv2.imread('images/handbw.png',0)\n",
    "w, h = template.shape[::-1]\n",
    "\n",
    "template2 = cv2.imread('images/fistbw2.png',0)\n",
    "w2, h2 = template2.shape[::-1]\n",
    "\n",
    "template3 = cv2.imread('images/waving.png',0)\n",
    "w3, h3 = template3.shape[::-1]\n",
    "\n",
    "\n",
    "def mySkinDetect(src):\n",
    "    # Surveys of skin color modeling and detection techniques:\n",
    "    # 1. Vezhnevets, Vladimir, Vassili Sazonov, and Alla Andreeva. \"A survey on pixel-based skin color detection techniques.\" Proc. Graphicon. Vol. 3. 2003.\n",
    "    # 2. Kakumanu, Praveen, Sokratis Makrogiannis, and Nikolaos Bourbakis. \"A survey of skin-color modeling and detection methods.\" Pattern recognition 40.3 (2007): 1106-1122.\n",
    "    dst = np.zeros((src.shape[0], src.shape[1], 1), dtype = \"uint8\")\n",
    "    for i in range(src.shape[0]):\n",
    "        for j in range(src.shape[1]):\n",
    "            #b,g,r = src[i,j]\n",
    "            b = int(src[i,j][0])\n",
    "            g = int(src[i,j][1])\n",
    "            r = int(src[i,j][2])\n",
    "            if(r>95 and g>40 and b>20 and max(r,g,b)-min(r,g,b)>15 and abs(r-g)>15 and r>g and r>b):\n",
    "                dst[i,j] = 255\n",
    "    return dst\n",
    "\n",
    "def myFrameDifferencing(prev, curr):\n",
    "    # For more information on operation with arrays: \n",
    "    # http://docs.opencv.org/modules/core/doc/operations_on_arrays.html\n",
    "    dst = cv2.absdiff(prev, curr)\n",
    "    dst = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "    _, dst = cv2.threshold(dst, 50, 255, cv2.THRESH_BINARY)\n",
    "    return dst\n",
    "\n",
    "def myMotionEnergy(mh):\n",
    "    # the window of time is 3\n",
    "    mh0 = mh[0]\n",
    "    mh1 = mh[1]\n",
    "    mh2 = mh[2]\n",
    "    dst = np.zeros((mh0.shape[0], mh0.shape[1], 1), dtype = \"uint8\")\n",
    "    for i in range(mh0.shape[0]):\n",
    "        for j in range(mh0.shape[1]):\n",
    "            if mh0[i,j] == 255 or mh1[i,j] == 255 or mh2[i,j] == 255:\n",
    "                dst[i,j] = 255\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    #Thresholds\n",
    "    threshold = 0.6\n",
    "    threshold_d = 0.4\n",
    "    #if not successful, exit program\n",
    "    if not cap.isOpened():\n",
    "        print(\"Cannot open the video cam\")\n",
    "        return -1\n",
    "    \n",
    "    # read a first frame from video\n",
    "    success, prev_frame = cap.read()\n",
    "    \n",
    "    #if not successful, exit program\n",
    "    if not success:\n",
    "        print(\"Cannot read a frame from video stream\")\n",
    "        return -1\n",
    "    \n",
    "    \n",
    "    cv2.namedWindow(\"frame\", cv2.WINDOW_AUTOSIZE)\n",
    "    \n",
    "    #Setting up Prev Frame for Frame Differencing\n",
    "    prev_frame = cv2.resize(prev_frame,(450,300))\n",
    "    cropimage = prev_frame[50:160, 50:160]\n",
    "    fMH1 = np.zeros((cropimage.shape[0], cropimage.shape[1], 1), dtype = \"uint8\")\n",
    "    fMH2 = fMH1.copy()\n",
    "    fMH3 = fMH1.copy()\n",
    "    myMotionHistory = deque([fMH1, fMH2, fMH3]) \n",
    "    \n",
    "    while(True):\n",
    "        success, curr_frame = cap.read()\n",
    "        curr_frame = cv2.resize(curr_frame,(450,300))\n",
    "        if not success:\n",
    "            print(\"Cannot read a frame from video stream\")\n",
    "            break\n",
    "        \n",
    "        #Setting a dedicated area for gesture recognition\n",
    "        cv2.rectangle(curr_frame, (50, 50), (160, 160), (0, 255, 0), 0)\n",
    "        crop_image = curr_frame[50:160, 50:160]\n",
    "            \n",
    "        # Frame differencing\n",
    "        frameDest = myFrameDifferencing(cropimage, crop_image)\n",
    "        #cv2.imshow('myFrameDifferencing',frameDest)\n",
    "\n",
    "        # Visualizing motion history\n",
    "        myMotionHistory.popleft()\n",
    "        myMotionHistory.append(frameDest)\n",
    "        myMH = myMotionEnergy(myMotionHistory)\n",
    "        cv2.imshow('myMotionHistory',myMH)\n",
    "    \n",
    "        # Skin color detection\n",
    "        mySkin = mySkinDetect(crop_image)\n",
    "        cv2.imshow('mySkinDetect',mySkin)\n",
    "        \n",
    "        #Template Matching Formula\n",
    "        res = cv2.matchTemplate(mySkin,template,cv2.TM_CCOEFF_NORMED)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "        top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        \n",
    "        res2 = cv2.matchTemplate(mySkin,template2,cv2.TM_CCOEFF_NORMED)\n",
    "        min_val2, max_val2, min_loc2, max_loc2 = cv2.minMaxLoc(res2)\n",
    "        top_left2 = max_loc2\n",
    "        bottom_right2 = (top_left2[0] + w2, top_left2[1] + h2)\n",
    "        \n",
    "        res3 = cv2.matchTemplate(myMH, template3, cv2.TM_CCOEFF_NORMED)\n",
    "        min_val3, max_val3, min_loc2, max_loc2 = cv2.minMaxLoc(res3)\n",
    "        top_left3 = max_loc2\n",
    "        bottom_right3 = (top_left3[0] + w2, top_left3[1] + h2)\n",
    "        \n",
    "        #Recogizes Gesture if Res is Greater than Threshold for the gestures\n",
    "        if len(res):\n",
    "            location = np.where( res >= threshold)\n",
    "            for pt in zip(*location[::-1]):\n",
    "                #puting  rectangle on recognized erea \n",
    "                cv2.rectangle(curr_frame, top_left, bottom_right, (0,0,255), 2)\n",
    "                cv2.putText(curr_frame, 'paper', (50,50), cv2.FONT_HERSHEY_PLAIN, 1.0, (0,0,255))\n",
    "        \n",
    "        if len(res2):\n",
    "            location = np.where( res2 >= threshold)\n",
    "            for pt in zip(*location[::-1]):\n",
    "                #puting  rectangle on recognized erea \n",
    "                cv2.rectangle(curr_frame, top_left2, bottom_right2, (0,0,255), 2)\n",
    "                cv2.putText(curr_frame, 'rock', (50,50), cv2.FONT_HERSHEY_PLAIN, 1.0, (0,0,255))\n",
    "                \n",
    "        if len(res3):\n",
    "            location = np.where( res3 >= threshold_d)\n",
    "            for pt in zip(*location[::-1]):\n",
    "                #puting  rectangle on recognized erea \n",
    "                cv2.rectangle(curr_frame, top_left3, bottom_right3, (0,0,255), 2)\n",
    "                cv2.putText(curr_frame, 'WAVING', (50,50), cv2.FONT_HERSHEY_PLAIN, 1.0, (0,0,255))\n",
    "        \n",
    "        #Show Frame\n",
    "        cv2.imshow('frame',curr_frame)\n",
    "\n",
    "        #Set Previous frame as old current frame\n",
    "        prev_frame = curr_frame\n",
    "        \n",
    "        # wait for 'q' key press. If 'q' key is pressed, break loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "            \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
